import os
import sys
import joblib
import pandas as pd
import numpy as np
import re
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from tensorflow.keras.models import Sequential, save_model, load_model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.callbacks import EarlyStopping

# Keras ë¡œë“œ ì‹œ ê²½ê³  ë©”ì‹œì§€ ë°©ì§€
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# --- 0. ì „ì—­ ë³€ìˆ˜ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì • (íŒŒì¼ëª… ì¼ì¹˜ í™•ì¸ ì™„ë£Œ) ---
DATA_FILE = 'ald_data.csv'  # â­ ì´ ì´ë¦„ìœ¼ë¡œ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
MODEL_PATH = 'improved_ald_mimo_model.h5'
PREPROCESSOR_PATH = 'ald_preprocessor.joblib'

# ì…ë ¥/ì¶œë ¥ ì»¬ëŸ¼ ì •ì˜
NUMERICAL_FEATURES = [
    'Precursor_Pulse_Time', 'Co_reactant_Pulse_Time', 'Cycles', 'Temperature',
    'Pressure', 'Purge_Time', 'Purge_Gas_Flow_Rate', 'Aspect_Ratio'
]
CATEGORICAL_FEATURES = ['Precursor', 'Co-reactant', 'Purge Gas']
X_COLS_ORDER = NUMERICAL_FEATURES + CATEGORICAL_FEATURES

TARGET_FEATURES = ['Thickness', 'Step_Coverage', 'Uniformity_Range', 'GPC', 'Density']
TARGET_FEATURES_DISPLAY = {
    'Thickness': 'Thickness (nm)', 
    'Step_Coverage': 'Step Coverage (%)', 
    'Uniformity_Range': 'Uniformity Range (%)', 
    'GPC': 'GPC (A/cycle)', 
    'Density': 'Density (g/cmÂ³)'
}

# --- ì•ˆì „í•œ NumPy ë°°ì—´ ë³€í™˜ í•¨ìˆ˜ ---
def to_dense(X):
    """ê°ì²´ê°€ 'toarray' ë©”ì„œë“œë¥¼ ê°€ì§€ë©´ í˜¸ì¶œí•˜ê³ , ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤."""
    if hasattr(X, 'toarray'):
        return X.toarray()
    return X


# --- 1. ë°ì´í„° í´ë¦¬ë‹ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---

def normalize_col_name(col):
    col_name = re.sub(r'\s*\([^)]*\)', '', col).strip() 
    col_name = re.sub(r'[^a-zA-Z0-9_]', '_', col_name).strip('_')
    
    # ëª…ì‹œì  ì´ë¦„ ë§¤í•‘ (ê°•ë ¥í•œ í˜¸í™˜ì„± í™•ë³´)
    if 'Precursor' == col_name or 'Precursor_Pulse_Time' in col_name: return 'Precursor_Pulse_Time' if 'Pulse_Time' in col_name else 'Precursor'
    if 'Co_reactant' == col_name or 'Co_reactant_Pulse_Time' in col_name: return 'Co_reactant_Pulse_Time' if 'Pulse_Time' in col_name else 'Co-reactant'
    if 'Purge_Gas' == col_name: return 'Purge Gas'
    if 'Temperature' in col_name: return 'Temperature'
    if 'Pressure' in col_name: return 'Pressure'
    if 'Aspect_Ratio' in col_name: return 'Aspect_Ratio'
    if 'Cycles' in col_name: return 'Cycles'
    if 'Purge_Time' in col_name: return 'Purge_Time'
    if 'Purge_Gas_Flow_Rate' in col_name: return 'Purge_Gas_Flow_Rate'
    if 'Thickness' in col_name: return 'Thickness'
    if 'GPC' in col_name: return 'GPC'
    if 'Density' in col_name: return 'Density'
    if 'Uniformity' in col_name: return 'Uniformity_Raw'
    if 'Step_Coverage' in col_name: return 'Step_Coverage_Raw'
    
    return col_name

def clean_data(df_raw):
    df_raw.columns = [normalize_col_name(col) for col in df_raw.columns]
    df = df_raw.copy()
    
    df = df.drop(columns=['Aspect_Ratio', 'Leakage_Current_Density', 'Dielectric_Constant', 
                          'Breakdown_Field', 'Paper_Title', 'Surface_Roughness', 
                          'Precursor_Flow_Rate', 'Co_reactant_Flow_Rate', 'ID'], errors='ignore')

    cols_to_convert = ['Precursor_Pulse_Time', 'Co_reactant_Pulse_Time', 'Cycles', 'Thickness']
    for col in cols_to_convert:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    def extract_aspect_ratio_from_step_coverage(raw_value):
        if pd.isna(raw_value): return np.nan
        s = str(raw_value)
        if 'AR' in s:
            match = re.search(r'AR[\s=]*([\d\.\s,]+)', s)
            if match:
                number_str = match.group(1).replace(' ', '').replace(',', '')
                numbers = re.findall(r'[\d\.]+', number_str)
                float_numbers = [float(n) for n in numbers if n]
                return max(float_numbers) if float_numbers else np.nan
        return np.nan
    
    if 'Aspect_Ratio' not in df.columns or df['Aspect_Ratio'].isnull().all():
        df['Aspect_Ratio'] = df['Step_Coverage_Raw'].apply(extract_aspect_ratio_from_step_coverage)
    else:
        df['Aspect_Ratio'] = pd.to_numeric(df['Aspect_Ratio'], errors='coerce')
        df['AR_Extracted'] = df['Step_Coverage_Raw'].apply(extract_aspect_ratio_from_step_coverage)
        df['Aspect_Ratio'] = df['Aspect_Ratio'].fillna(df['AR_Extracted'])
        df = df.drop(columns=['AR_Extracted'], errors='ignore')

    def extract_step_coverage_robust(raw_value):
        if pd.isna(raw_value): return np.nan
        s = re.sub(r'[^0-9\.\,\-\s\(\)%]', '', str(raw_value).strip()).replace('%', '')
        numbers = re.findall(r'[\d\.]+', s)
        try:
            float_numbers = [float(n) for n in numbers if n]
            return max(float_numbers) if float_numbers else np.nan
        except:
            return np.nan
    df['Step_Coverage'] = df['Step_Coverage_Raw'].apply(extract_step_coverage_robust)
    
    def extract_uniformity_range(raw_value):
        if pd.isna(raw_value): return np.nan
        s = re.sub(r'[^\d\.]', '', str(raw_value).strip())
        try:
            return float(s)
        except:
            return np.nan
    df['Uniformity_Range'] = df['Uniformity_Raw'].apply(extract_uniformity_range)
    
    df = df.drop(columns=['Uniformity_Raw', 'Step_Coverage_Raw'], errors='ignore')

    df_final = df[X_COLS_ORDER + TARGET_FEATURES].copy()
    df_clean = df_final.dropna(subset=X_COLS_ORDER + TARGET_FEATURES).copy()
    
    return df_clean


# --- 2. AI ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ í•¨ìˆ˜ ---

def train_and_save_model():
    """ë°ì´í„°ë¥¼ í´ë¦¬ë‹í•˜ê³  AI ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„ ì €ì¥í•©ë‹ˆë‹¤."""
    print("--- ğŸ› ï¸ AI ëª¨ë¸ í•™ìŠµ/ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ---")
    
    try:
        df_raw = pd.read_csv(DATA_FILE, encoding='utf-8')
    except:
        df_raw = pd.read_csv(DATA_FILE, encoding='cp949')

    df_clean = clean_data(df_raw)
    
    X = df_clean[X_COLS_ORDER]
    Y = df_clean[TARGET_FEATURES]
    
    print(f"âœ… ë°ì´í„° í´ë¦¬ë‹ ì™„ë£Œ. ìµœì¢… í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: {len(df_clean)}ê°œ")

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

    numerical_transformer = StandardScaler()
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, NUMERICAL_FEATURES),
            ('cat', categorical_transformer, CATEGORICAL_FEATURES)
        ]
    )
    X_train_processed = preprocessor.fit_transform(X_train)
    
    joblib.dump(preprocessor, PREPROCESSOR_PATH)
    print("âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (.joblib) ì €ì¥ ì™„ë£Œ.")

    input_dim = to_dense(X_train_processed).shape[1] 
    output_dim = Y_train.shape[1]
    
    lr_schedule = ExponentialDecay(0.001, decay_steps=1000, decay_rate=0.96, staircase=True)
    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

    improved_model = Sequential([
        Dense(128, activation='relu', input_shape=(input_dim,)),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(output_dim, activation='linear')
    ])

    improved_model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
        loss='mse', 
        metrics=['mae'] 
    )

    print("--- AI ëª¨ë¸ í•™ìŠµ ì‹œì‘ (150 Epochs) ---")
    improved_model.fit(
        to_dense(X_train_processed), 
        Y_train.values,
        epochs=150, 
        batch_size=32,
        validation_split=0.2, 
        callbacks=[early_stopping],
        verbose=0
    )
    print("--- AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---")

    save_model(improved_model, MODEL_PATH)
    print(f"âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ({MODEL_PATH}) ì €ì¥ ì™„ë£Œ.")
    
    return improved_model, preprocessor


# --- 3. ì½˜ì†” ê³„ì‚° ë° ì¶œë ¥ í•¨ìˆ˜ ---

def run_single_prediction_test(model, preprocessor):
    """íŠ¹ì • ì…ë ¥ì— ëŒ€í•œ AI ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í„°ë¯¸ë„ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    # --- â­ ê³„ì‚°ì— ì‚¬ìš©í•  ì…ë ¥ ì¡°ê±´ (ì´ ë¶€ë¶„ì„ ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”) â­ ---
    test_data = pd.DataFrame({
        'Precursor_Pulse_Time': [0.1], 
        'Co_reactant_Pulse_Time': [0.1], 
        'Cycles': [500.0], 
        'Temperature': [300],
        'Pressure': [0.3], 
        'Purge_Time': [5.0], 
        'Purge_Gas_Flow_Rate': [200.0], 
        'Aspect_Ratio': [100.0],
        'Precursor': ['TMA'], 
        'Co-reactant': ['H2O'], 
        'Purge Gas': ['N2']
    })
    
    # ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
    X_test_processed = preprocessor.transform(test_data)
    Y_predicted = model.predict(to_dense(X_test_processed))[0]
    
    # --- ê²°ê³¼ ì¶œë ¥ ---
    print("\n" + "="*50)
    print("--- ğŸ§ª ALD ê³µì • AI ì˜ˆì¸¡ ê³„ì‚° ê²°ê³¼ (VS Code í„°ë¯¸ë„) ---")
    print("="*50)
    print("ì…ë ¥ ì¡°ê±´:")
    for key, value in test_data.iloc[0].items():
        print(f"  {key:<25}: {value}")
        
    print("\n\nğŸ”¥ ì˜ˆì¸¡ëœ ë°•ë§‰ íŠ¹ì„± (Y):")
    for i, target in enumerate(TARGET_FEATURES):
        display_name = TARGET_FEATURES_DISPLAY.get(target, target)
        print(f"  {display_name:<25}: {Y_predicted[i]:.4f}")
    print("="*50)

# --- 4. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---

def load_ai_assets():
    """ì €ì¥ëœ AI ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë¥¼ ë¡œë“œ"""
    global loaded_model, loaded_preprocessor
    try:
        loaded_model = load_model(MODEL_PATH) 
        loaded_preprocessor = joblib.load(PREPROCESSOR_PATH)
        return loaded_model, loaded_preprocessor
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ Keras ë¹„í˜¸í™˜ì„± ë¬¸ì œì…ë‹ˆë‹¤. ì—ëŸ¬: {e}")
        return None, None

if __name__ == '__main__':
    loaded_model, loaded_preprocessor = None, None
    
    # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í•™ìŠµ ë° ì €ì¥ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰
    if not os.path.exists(MODEL_PATH) or not os.path.exists(PREPROCESSOR_PATH):
        if not os.path.exists(DATA_FILE):
             print(f"âŒ ì˜¤ë¥˜: í•™ìŠµ ë°ì´í„° íŒŒì¼ ({DATA_FILE})ì´ í˜„ì¬ í´ë”ì— ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
             sys.exit(1)
        # í•™ìŠµ ë° ì €ì¥ ì‹¤í–‰
        loaded_model, loaded_preprocessor = train_and_save_model()
    
    # íŒŒì¼ì´ ìˆê±°ë‚˜ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ë¡œë“œ ì‹œë„
    if loaded_model is None or loaded_preprocessor is None:
        loaded_model, loaded_preprocessor = load_ai_assets()

    # --- ìµœì¢… ê³„ì‚° ì‹¤í–‰ ---
    if loaded_model is not None and loaded_preprocessor is not None:
        run_single_prediction_test(loaded_model, loaded_preprocessor)
    else:
        print("âŒ ì‹¬ê°í•œ ì˜¤ë¥˜: AI ëª¨ë¸ì´ ìµœì¢…ì ìœ¼ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")