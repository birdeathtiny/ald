import streamlit as st
import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
import re
import plotly.graph_objects as go
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.compose import ColumnTransformer
from tensorflow.keras.models import Sequential, save_model, load_model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers.schedules import ExponentialDecay

# Keras ë¡œë“œ ì‹œ ê²½ê³  ë©”ì‹œì§€ ë°©ì§€
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# --- 0. ì „ì—­ ë³€ìˆ˜ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì • ---
DATA_FILE = 'ald_data.csv'  # â­ ì´ ì´ë¦„ìœ¼ë¡œ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
MODEL_PATH = 'improved_ald_mimo_model.h5'
PREPROCESSOR_PATH = 'ald_preprocessor.joblib'
Y_SCALER_PATH = 'y_minmax_scaler.joblib' 

# ì…ë ¥/ì¶œë ¥ ì»¬ëŸ¼ ì •ì˜
NUMERICAL_FEATURES = [
    'Precursor_Pulse_Time', 'Co_reactant_Pulse_Time', 'Cycles', 'Temperature',
    'Pressure', 'Purge_Time', 'Purge_Gas_Flow_Rate', 'Aspect_Ratio'
]
CATEGORICAL_FEATURES = ['Precursor', 'Co-reactant', 'Purge Gas']
X_COLS_ORDER = NUMERICAL_FEATURES + CATEGORICAL_FEATURES

TARGET_FEATURES = ['Thickness', 'Step_Coverage', 'Uniformity_Range', 'GPC', 'Density']
TARGET_FEATURES_DISPLAY = {
    'Thickness': 'Thickness (nm)', 
    'Step_Coverage': 'Step Coverage (%)', 
    'Uniformity_Range': 'Uniformity Range (%)', 
    'GPC': 'GPC (A/cycle)', 
    'Density': 'Density (g/cmÂ³)'
}
DEFAULT_PRECURSORS = ['TMA', 'SiH4', 'TiCl4']
DEFAULT_COREACTANTS = ['H2O', 'O2', 'O3 + N2']
DEFAULT_PURGE_GASES = ['N2', 'Ar']


# --- ì•ˆì „í•œ NumPy ë°°ì—´ ë³€í™˜ í•¨ìˆ˜ ---
def to_dense(X):
    if hasattr(X, 'toarray'):
        return X.toarray()
    return X


# --- 1. ë°ì´í„° í´ë¦¬ë‹ ë° ëª¨ë¸ í•™ìŠµ/ì €ì¥ ë¡œì§ (í•¨ìˆ˜ë“¤) ---

def normalize_col_name(col):
    # íŒŒì¼ëª… í´ë¦¬ë‹ ë¡œì§ (ìƒëµí•˜ì§€ ì•Šê³  ì™„ì „í•˜ê²Œ í¬í•¨)
    col_name = re.sub(r'\s*\([^)]*\)', '', col).strip() 
    col_name = re.sub(r'[^a-zA-Z0-9_]', '_', col_name).strip('_')
    
    if 'Precursor' == col_name or 'Precursor_Pulse_Time' in col_name: return 'Precursor_Pulse_Time' if 'Pulse_Time' in col_name else 'Precursor'
    if 'Co_reactant' == col_name or 'Co_reactant_Pulse_Time' in col_name: return 'Co_reactant_Pulse_Time' if 'Pulse_Time' in col_name else 'Co-reactant'
    if 'Purge_Gas' == col_name: return 'Purge Gas'
    if 'Temperature' in col_name: return 'Temperature'
    if 'Pressure' in col_name: return 'Pressure'
    if 'Aspect_Ratio' in col_name: return 'Aspect_Ratio'
    if 'Cycles' in col_name: return 'Cycles'
    if 'Purge_Time' in col_name: return 'Purge_Time'
    if 'Purge_Gas_Flow_Rate' in col_name: return 'Purge_Gas_Flow_Rate'
    if 'Thickness' in col_name: return 'Thickness'
    if 'GPC' in col_name: return 'GPC'
    if 'Density' in col_name: return 'Density'
    if 'Uniformity' in col_name: return 'Uniformity_Raw'
    if 'Step_Coverage' in col_name: return 'Step_Coverage_Raw'
    
    return col_name

def clean_data(df_raw):
    df_raw.columns = [normalize_col_name(col) for col in df_raw.columns]
    df = df_raw.copy()
    
    df = df.drop(columns=['Aspect_Ratio', 'Leakage_Current_Density', 'Dielectric_Constant', 
                          'Breakdown_Field', 'Paper_Title', 'Surface_Roughness', 
                          'Precursor_Flow_Rate', 'Co_reactant_Flow_Rate', 'ID'], errors='ignore')

    cols_to_convert = ['Precursor_Pulse_Time', 'Co_reactant_Pulse_Time', 'Cycles', 'Thickness']
    for col in cols_to_convert:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    def extract_aspect_ratio_from_step_coverage(raw_value):
        if pd.isna(raw_value): return np.nan
        s = str(raw_value)
        if 'AR' in s:
            match = re.search(r'AR[\s=]*([\d\.\s,]+)', s)
            if match:
                number_str = match.group(1).replace(' ', '').replace(',', '')
                numbers = re.findall(r'[\d\.]+', number_str)
                float_numbers = [float(n) for n in numbers if n]
                return max(float_numbers) if float_numbers else np.nan
        return np.nan
    
    if 'Aspect_Ratio' not in df.columns or df['Aspect_Ratio'].isnull().all():
        df['Aspect_Ratio'] = df['Step_Coverage_Raw'].apply(extract_aspect_ratio_from_step_coverage)
    else:
        df['Aspect_Ratio'] = pd.to_numeric(df['Aspect_Ratio'], errors='coerce')
        df['AR_Extracted'] = df['Step_Coverage_Raw'].apply(extract_aspect_ratio_from_step_coverage)
        df['Aspect_Ratio'] = df['Aspect_Ratio'].fillna(df['AR_Extracted'])
        df = df.drop(columns=['AR_Extracted'], errors='ignore')

    def extract_step_coverage_robust(raw_value):
        if pd.isna(raw_value): return np.nan
        s = re.sub(r'[^0-9\.\,\-\s\(\)%]', '', str(raw_value).strip()).replace('%', '')
        numbers = re.findall(r'[\d\.]+', s)
        try:
            float_numbers = [float(n) for n in numbers if n]
            return max(float_numbers) if float_numbers else np.nan
        except:
            return np.nan
    df['Step_Coverage'] = df['Step_Coverage_Raw'].apply(extract_step_coverage_robust)
    
    def extract_uniformity_range(raw_value):
        if pd.isna(raw_value): return np.nan
        s = re.sub(r'[^\d\.]', '', str(raw_value).strip())
        try:
            return float(s)
        except:
            return np.nan
    df['Uniformity_Range'] = df['Uniformity_Raw'].apply(extract_uniformity_range)
    
    df = df.drop(columns=['Uniformity_Raw', 'Step_Coverage_Raw'], errors='ignore')

    df_final = df[X_COLS_ORDER + TARGET_FEATURES].copy()
    df_clean = df_final.dropna(subset=X_COLS_ORDER + TARGET_FEATURES).copy()
    
    return df_clean

@st.cache_resource
def train_and_save_model():
    """ëª¨ë¸ í•™ìŠµ ë° íŒŒì¼ ì €ì¥ (Streamlit ìºì‹œ í™œìš©)"""
    st.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ë° AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. ({DATA_FILE})")
    
    try:
        df_raw = pd.read_csv(DATA_FILE, encoding='utf-8')
    except:
        df_raw = pd.read_csv(DATA_FILE, encoding='cp949')

    df_clean = clean_data(df_raw)
    
    X_train, X_test, Y_train, Y_test = train_test_split(df_clean[X_COLS_ORDER], df_clean[TARGET_FEATURES], test_size=0.2, random_state=42)

    # 1. X ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ (StandardScaler)
    numerical_transformer = StandardScaler()
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')
    preprocessor = ColumnTransformer(
        transformers=[('num', numerical_transformer, NUMERICAL_FEATURES),('cat', categorical_transformer, CATEGORICAL_FEATURES)]
    )
    X_train_processed = preprocessor.fit_transform(X_train)
    joblib.dump(preprocessor, PREPROCESSOR_PATH)

    # 2. Y íƒ€ê²Ÿ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (MinMaxScaler for 0-1 range)
    Y_scaler = MinMaxScaler()
    Y_train_scaled = Y_scaler.fit_transform(Y_train)
    joblib.dump(Y_scaler, Y_SCALER_PATH)

    # 3. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ
    input_dim = to_dense(X_train_processed).shape[1] 
    output_dim = Y_train.shape[1]
    
    improved_model = Sequential([
        Dense(128, activation='relu', input_shape=(input_dim,)),
        Dropout(0.2), Dense(64, activation='relu'), Dropout(0.2), Dense(32, activation='relu'),
        Dense(output_dim, activation='relu') 
    ])
    improved_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    # í•™ìŠµ
    improved_model.fit(to_dense(X_train_processed), Y_train_scaled, epochs=150, batch_size=32, validation_split=0.2, verbose=0)
    save_model(improved_model, MODEL_PATH)
    
    st.success(f"âœ… AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ì´ {len(df_clean)}ê°œ ë°ì´í„° ì‚¬ìš©)")
    return improved_model, preprocessor, Y_scaler

# --- 2. AI ì˜ˆì¸¡ í•¨ìˆ˜ (í†µí•©) ---

@st.cache_resource
def load_ai_assets():
    """ëª¨ë¸ íŒŒì¼ ë¡œë“œ ë˜ëŠ” í•™ìŠµ/ìƒì„± í›„ ë¡œë“œ"""
    if not os.path.exists(MODEL_PATH) or not os.path.exists(PREPROCESSOR_PATH) or not os.path.exists(Y_SCALER_PATH):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ í•™ìŠµ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
        return train_and_save_model()
    else:
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•©ë‹ˆë‹¤.
        try:
            model = tf.keras.models.load_model(MODEL_PATH)
            preprocessor = joblib.load(PREPROCESSOR_PATH)
            y_scaler = joblib.load(Y_SCALER_PATH)
            return model, preprocessor, y_scaler
        except Exception as e:
            st.error(f"âŒ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ì„ ì‚­ì œí•˜ê³  ì¬ì‹¤í–‰í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")
            st.stop()

def predict_ald_properties(input_df, model, preprocessor, y_scaler):
    """ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ AI ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # X ì…ë ¥ ì „ì²˜ë¦¬
    X_processed = preprocessor.transform(input_df[X_COLS_ORDER])
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    Y_predicted_scaled = model.predict(to_dense(X_processed))[0]
    
    # ê²°ê³¼ ì—­ë³€í™˜ (ì‹¤ì œ ë¬¼ë¦¬ì  ë‹¨ìœ„ë¡œ ë³µì›)
    Y_predicted_original = y_scaler.inverse_transform(Y_predicted_scaled.reshape(1, -1))[0]
    
    results_df = pd.DataFrame({'íŠ¹ì„±': list(TARGET_FEATURES_DISPLAY.values()),'ì˜ˆì¸¡ ê°’': [f"{val:.4f}" for val in Y_predicted_original]})
    
    return results_df, Y_predicted_original


# --- 3. Streamlit UI êµ¬ì„± (ë©”ì¸ ì‹¤í–‰) ---

st.set_page_config(page_title="ALD ê³µì • AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ§ª 3D ë°˜ë„ì²´ ALD ê³µì • AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

# ëª¨ë¸ ë¡œë“œ/í•™ìŠµ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ë©°, Streamlitì˜ ìºì‹œ ë•ë¶„ì— í•œ ë²ˆë§Œ ì‹¤í–‰ë¨)
model, preprocessor, y_scaler = load_ai_assets()

# --- ì‚¬ì´ë“œë°”: ì…ë ¥ íŒ¨ë„ ---
with st.sidebar:
    st.header("ê³µì • ì¡°ê±´ ì…ë ¥ (X)")
    st.markdown("---")

    # ì…ë ¥ í•„ë“œ
    precursor = st.selectbox("Precursor", DEFAULT_PRECURSORS, index=0)
    co_reactant = st.selectbox("Co-reactant", DEFAULT_COREACTANTS, index=0)
    purge_gas = st.selectbox("Purge Gas", DEFAULT_PURGE_GASES, index=0)
    
    st.markdown("---")
    st.subheader("ìˆ˜ì¹˜í˜• ë³€ìˆ˜")
    
    temperature = st.slider("Temperature (â„ƒ)", min_value=100, max_value=400, value=300, step=1)
    pressure = st.number_input("Pressure (torr)", min_value=0.01, max_value=10.0, value=0.3, step=0.01)
    aspect_ratio = st.number_input("Aspect Ratio (AR)", min_value=1.0, max_value=500.0, value=10.0, step=1.0)
    
    st.markdown("---")
    
    prec_pulse = st.number_input("Precursor Pulse Time (s)", min_value=0.01, max_value=10.0, value=0.1, step=0.01)
    co_pulse = st.number_input("Co-reactant Pulse Time (s)", min_value=0.01, max_value=10.0, value=0.1, step=0.01)
    cycles = st.number_input("Cycles (n)", min_value=1, max_value=1000, value=500, step=10)
    purge_time = st.number_input("Purge Time (s)", min_value=0.1, max_value=20.0, value=5.0, step=0.1)
    purge_flow = st.number_input("Purge Gas Flow Rate (ccm)", min_value=50.0, max_value=500.0, value=200.0, step=10.0)


# --- ë©”ì¸ í˜ì´ì§€: ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ ---

# 1. ì…ë ¥ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ í†µí•©
input_data_df = pd.DataFrame({
    'Precursor_Pulse_Time': [prec_pulse], 'Co_reactant_Pulse_Time': [co_pulse], 'Cycles': [cycles], 'Temperature': [temperature],
    'Pressure': [pressure], 'Purge_Time': [purge_time], 'Purge_Gas_Flow_Rate': [purge_flow], 'Aspect_Ratio': [aspect_ratio],
    'Precursor': [precursor], 'Co-reactant': [co_reactant], 'Purge Gas': [purge_gas]
})

# 2. ì˜ˆì¸¡ ë²„íŠ¼
if st.button("AI ì˜ˆì¸¡ ê³„ì‚° ì‹¤í–‰", type="primary", use_container_width=True):
    # ì˜ˆì¸¡ í•¨ìˆ˜ í˜¸ì¶œ
    results_df, Y_predicted_original = predict_ald_properties(input_data_df, model, preprocessor, y_scaler)

    if results_df is not None:
        st.subheader("ì˜ˆì¸¡ëœ ë°•ë§‰ íŠ¹ì„± ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        
        # 3. í…Œì´ë¸” ì¶œë ¥
        with col1:
            st.dataframe(results_df, hide_index=True, use_container_width=True)
            st.success("âœ… AI ì˜ˆì¸¡ ê³„ì‚° ì™„ë£Œ")

        # 4. Plotly ë ˆì´ë” ì°¨íŠ¸ ì¶œë ¥
        with col2:
            fig = go.Figure(data=[
                go.Scatterpolar(
                    r=Y_predicted_original,
                    theta=list(TARGET_FEATURES_DISPLAY.values()),
                    fill='toself',
                    name='AI ì˜ˆì¸¡ ê²°ê³¼'
                )
            ],
            layout=go.Layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, np.max(Y_predicted_original) * 1.2]) 
                ),
                showlegend=False,
                height=450
            ))
            st.plotly_chart(fig, use_container_width=True)
            
        st.markdown("---")
        st.caption("ê²°ê³¼ í•´ì„: Min-Max Scalingê³¼ ReLU í™œì„±í™” í•¨ìˆ˜ê°€ ì ìš©ë˜ì–´ GPC/Step Coverage ë“±ì€ 0 ë¯¸ë§Œìœ¼ë¡œ ì˜ˆì¸¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ 0ì— ê°€ê¹ë‹¤ë©´, í•´ë‹¹ ì¡°ê±´ì€ ì¦ì°©ì— ë¹„íš¨ìœ¨ì ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")