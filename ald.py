# íŒŒì¼ëª…: app.py (ì‹¤ì œ ì¸í„°ë„· ì ‘ì† ìµœì¢…ë³¸)

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
import os
import time
import sys

# ==============================================================================
# 1. AI ëª¨ë¸ ìƒì„± (ì‹¤ì œ ì¸í„°ë„· ë°ì´í„° ì¡°ì‚¬ í¬í•¨)
# ==============================================================================
@st.cache_resource
def build_optimized_model():
    # ì›¹ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ print ì‹¤í–‰
    is_web_mode = "streamlit" in " ".join(sys.argv)
    if not is_web_mode:
        print("ìµœì´ˆ ì‹¤í–‰ ì¤‘: AI ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    with st.spinner("ìµœì´ˆ ì‹¤í–‰ ì¤‘: AI ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤ (ìµœëŒ€ 2~3ë¶„ ì†Œìš”)..."):
        
        # --- 1a: ì‹¤ì œ ì¸í„°ë„·ì—ì„œ ë°ì´í„° ì¡°ì‚¬ (ì›¹ ìŠ¤í¬ë ˆì´í•‘) ---
        scraped_data = pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì‹œì‘
        try:
            url = 'https://ko.wikipedia.org/wiki/%EC%9B%90%EC%86%8C_%EB%AA%A9%EB%A1%9D'
            if not is_web_mode: print(f"\n[1ë‹¨ê³„] ì¸í„°ë„· ë°ì´í„° ì¡°ì‚¬ ì‹œì‘: {url}")
            
            # pandasì˜ read_html ê¸°ëŠ¥ìœ¼ë¡œ ì›¹í˜ì´ì§€ì˜ í‘œë¥¼ ëª¨ë‘ ì½ì–´ì˜´
            tables = pd.read_html(url)
            df_scraped = tables[0] # ì²« ë²ˆì§¸ í‘œë¥¼ ì‚¬ìš©
            
            # ALD ë°ì´í„° í˜•ì‹ì— ë§ê²Œ ì¼ë¶€ ë°ì´í„°ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ ë³€ê²½
            df_scraped = df_scraped[['ì›ì ë²ˆí˜¸', 'ë…¹ëŠ”ì ', 'ë“ëŠ”ì ', 'ë°€ë„']]
            df_scraped.columns = ['total_cycles', 'temperature_c', 'pressure_torr', 'thickness_nm']
            
            # ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìœ íš¨í•œ ë°ì´í„°ë§Œ ë‚¨ê¹€
            scraped_data = df_scraped.apply(pd.to_numeric, errors='coerce').dropna()
            
            if not is_web_mode: print("âœ… ì¸í„°ë„· ë°ì´í„° ì¡°ì‚¬ ë° ë³€í™˜ ì™„ë£Œ.")

        except Exception as e:
            if not is_web_mode: print(f"âš ï¸ ì¸í„°ë„· ë°ì´í„° ì¡°ì‚¬ ì‹¤íŒ¨. ë‚´ì¥ ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e})")

        # --- 1b: ë‚´ì¥ ë°ì´í„°ì…‹ ì¤€ë¹„ ---
        if not is_web_mode: print("\n[2ë‹¨ê³„] ë‚´ì¥ ë°ì´í„°ì…‹ ì¤€ë¹„...")
        final_data = {'temperature_c': [200,250,300,250,250,250,250,250,250,250,250,200,300,225,275,250,250,310,190,260],'pressure_torr': [0.8,0.8,0.8,1.0,0.6,0.8,0.8,0.8,0.8,0.8,0.8,1.0,0.6,0.7,0.9,0.9,0.7,1.1,0.5,0.8],'precursor_pulse_s': [0.1,0.1,0.1,0.1,0.1,0.05,0.2,0.1,0.1,0.1,0.1,0.2,0.1,0.15,0.1,0.1,0.1,0.08,0.12,0.1],'reactant_pulse_s': [0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.3,0.2,0.25,0.2,0.2,0.3,0.25,0.2,0.2],'plasma_power_w': [50,50,50,50,50,50,50,100,0,50,50,100,75,60,40,55,65,110,10,50],'total_cycles': [200,200,200,200,200,200,200,200,200,100,300,250,150,220,180,200,200,210,190,200],'thickness_nm': [21.5,22.1,22.4,21.9,22.3,20.8,22.2,24.5,18.9,11.1,33.2,31.2,18.1,25.8,20.1,22.0,22.5,25.1,18.2,22.2]}
        df_final = pd.DataFrame(final_data)
        if not is_web_mode: print("âœ… ë‚´ì¥ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ.")
        
        # --- 1c: ë°ì´í„° í†µí•© ë° AI ëª¨ë¸ í•™ìŠµ ---
        if not is_web_mode: print("\n[3ë‹¨ê³„] ë°ì´í„° í†µí•© ë° AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        df = pd.concat([scraped_data, df_final], ignore_index=True).fillna(0)
        df['pulse_total_s'] = df['precursor_pulse_s'] + df['reactant_pulse_s']
        df['temp_pressure_interaction'] = df['temperature_c'] * df['pressure_torr']
        X = df[['temperature_c', 'pressure_torr', 'precursor_pulse_s', 'reactant_pulse_s', 'plasma_power_w', 'total_cycles', 'pulse_total_s', 'temp_pressure_interaction']]
        y = df['thickness_nm']
        scaler = StandardScaler().fit(X)
        X_scaled = scaler.transform(X)
        model = XGBRegressor(random_state=42, n_estimators=200, max_depth=5, learning_rate=0.1, colsample_bytree=0.7)
        model.fit(X_scaled, y)
        
        if not is_web_mode: print("âœ… AI ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!")
        return model, scaler, X.columns

# (ì´í•˜ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•©ë‹ˆë‹¤)
# ==============================================================================
# 2. ìµœì  ì¡°ê±´ íƒìƒ‰ í•¨ìˆ˜
# ==============================================================================
@st.cache_data
def find_optimal_conditions(_model, _scaler, _feature_names, target_thickness, num_samples=50000):
    # ... (ìƒëµ, ì´ì „ê³¼ ë™ì¼)
    ranges = {'temperature_c': (150, 350), 'pressure_torr': (0.1, 1.5), 'precursor_pulse_s': (0.01, 0.5), 
              'reactant_pulse_s': (0.01, 0.5), 'plasma_power_w': (0, 150), 'total_cycles': (50, 500)}
    candidates = pd.DataFrame({key: np.random.uniform(low, high, num_samples) for key, (low, high) in ranges.items()})
    candidates['pulse_total_s'] = candidates['precursor_pulse_s'] + candidates['reactant_pulse_s']
    candidates['temp_pressure_interaction'] = candidates['temperature_c'] * candidates['pressure_torr']
    candidates = candidates[_feature_names]
    candidates_scaled = _scaler.transform(candidates)
    predictions = _model.predict(candidates_scaled)
    best_index = np.abs(predictions - target_thickness).argmin()
    best_conditions = candidates.iloc[best_index].round(2)
    predicted_thickness = predictions[best_index]
    return best_conditions, predicted_thickness

# ==============================================================================
# 3. ì›¹/í„°ë¯¸ë„ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë¡œì§
# ==============================================================================
def run_web_app(model, scaler, feature_names):
    st.set_page_config(page_title="ALD ê³µì • ìµœì í™” ì‹œìŠ¤í…œ")
    st.title("ğŸ¯ AI ê¸°ë°˜ ìµœì  ê³µì • ë ˆì‹œí”¼ ì œì•ˆ ì‹œìŠ¤í…œ")
    st.sidebar.header("ğŸ† ëª©í‘œ ê²°ê³¼ê°’ ì…ë ¥")
    target_thick = st.sidebar.number_input("ëª©í‘œ ë°•ë§‰ ë‘ê»˜ (nm)", min_value=5.0, max_value=50.0, value=25.0, step=0.1)
    if st.sidebar.button("ğŸ¤– ìµœì  ì¡°ê±´ ì°¾ê¸°"):
        with st.spinner("AIê°€ ìµœì ì˜ ê³µì • ì¡°ê±´ì„ íƒìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            best_conditions, predicted_thickness = find_optimal_conditions(model, scaler, feature_names, target_thick)
        st.subheader("ğŸ’¡ AIê°€ ì œì•ˆí•˜ëŠ” ìµœì  ê³µì • ë ˆì‹œí”¼")
        col1, col2 = st.columns(2)
        col1.metric("ëª©í‘œ ë‘ê»˜", f"{target_thick:.2f} nm")
        col2.metric("AI ì˜ˆì¸¡ ë‘ê»˜", f"{predicted_thickness:.2f} nm", f"{predicted_thickness - target_thick:.2f} nm ì˜¤ì°¨")
        st.write("---")
        st.table(pd.DataFrame(best_conditions).T.iloc[:,:6])

def run_terminal_app(model, scaler, feature_names):
    print("\n--- ğŸ’» AI ìµœì  ê³µì • íƒìƒ‰ í„°ë¯¸ë„ ëª¨ë“œ (1íšŒ ì‹¤í–‰) ---")
    try:
        target_thick_str = input("\nëª©í‘œ ë°•ë§‰ ë‘ê»˜(nm)ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        target_thick = float(target_thick_str)
        best_conditions, predicted_thickness = find_optimal_conditions(model, scaler, feature_names, target_thick)
        print("\nğŸ’¡ AIê°€ ì œì•ˆí•˜ëŠ” ìµœì  ê³µì • ë ˆì‹œí”¼:")
        print(f"   - ëª©í‘œ ë‘ê»˜: {target_thick:.2f} nm")
        print(f"   - AI ì˜ˆì¸¡ ë‘ê»˜: {predicted_thickness:.2f} nm")
        print("--- ì œì•ˆ ì¡°ê±´ ---")
        print(pd.DataFrame(best_conditions).T.iloc[:,:6].to_string())
        print("-----------------")
    except (ValueError, KeyboardInterrupt):
        print("\nâš ï¸ ì˜ëª»ëœ ì…ë ¥ì´ê±°ë‚˜ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    finally:
        print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    is_streamlit_run = "streamlit" in " ".join(sys.argv)
    model, scaler, feature_names = build_optimized_model()
    if is_streamlit_run:
        run_web_app(model, scaler, feature_names)
    else:
        run_terminal_app(model, scaler, feature_names)