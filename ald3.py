import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.multioutput import MultiOutputRegressor
import warnings

warnings.filterwarnings('ignore')

# --- 1. ë°ì´í„° ë¡œë”© ë° í´ë¦¬ë‹ í•¨ìˆ˜ ---
@st.cache_data # íŒŒì¼ ë‚´ìš©ì´ ê°™ìœ¼ë©´ ìºì‹œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ì†ë„ í–¥ìƒ
def load_and_clean_data(uploaded_file):
    """ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ë°ì´í„° í´ë¦¬ë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if uploaded_file is None:
        return None
    
    try:
        df = pd.read_csv(uploaded_file)
        
        numeric_cols_to_clean = [
            'T (oC)', 'P (mTorr)', 'F (sccm)', 'Knudsen Number (Kn)', 
            'Sticking Coefficient (s)', 'Step Coverage (SC, %)', 'Depo Rate (nm/cycle)', 
            'C/H Impurity (at.%)', 'Particle Density (cm-3)'
        ]

        for col in numeric_cols_to_clean:
            if col in df.columns:
                df[col] = df[col].astype(str).str.extract(r'(\d+\.?\d*)').astype(float)
        
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --- 2. ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ---
@st.cache_resource # ëª¨ë¸ì²˜ëŸ¼ í° ê°ì²´ëŠ” ë¦¬ì†ŒìŠ¤ ìºì‹œ ì‚¬ìš©
def train_model(df):
    """ì •ì œëœ ë°ì´í„°ë¡œ AI ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³ , ëª¨ë¸ê³¼ í‰ê°€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        input_columns = ['T (oC)', 'P (mTorr)', 'F (sccm)', 'T Level', 'Knudsen Number (Kn)', 'Sticking Coefficient (s)']
        output_columns = ['Step Coverage (SC, %)', 'Depo Rate (nm/cycle)', 'C/H Impurity (at.%)', 'Particle Density (cm-3)']
        categorical_features = ['T Level']

        df_cleaned = df.dropna(subset=input_columns + output_columns)
        if len(df_cleaned) < 10:
            st.warning("í•™ìŠµì— í•„ìš”í•œ ìœ íš¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return None, None

        X = df_cleaned[input_columns]
        Y = df_cleaned[output_columns]
        
        preprocessor = ColumnTransformer(
            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],
            remainder='passthrough'
        )

        model_pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)))
        ])

        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
        model_pipeline.fit(X_train, Y_train)
        
        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        predictions = model_pipeline.predict(X_test)
        evaluation_metrics = {}
        for i, col_name in enumerate(output_columns):
            mae = mean_absolute_error(Y_test.iloc[:, i], predictions[:, i])
            evaluation_metrics[col_name] = mae
            
        return model_pipeline, X, evaluation_metrics

    except KeyError as e:
        st.error(f"KeyError: CSV íŒŒì¼ì— í•„ìš”í•œ ì—´({e})ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    except Exception as e:
        st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# --- 3. ìµœì  ì¡°ê±´ íƒìƒ‰ í•¨ìˆ˜ ---
def find_optimal_conditions(model, original_X, optimization_target, num_simulations):
    """í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ ìµœì  ì¡°ê±´ì„ íƒìƒ‰í•©ë‹ˆë‹¤."""
    sim_data = {}
    for col in original_X.columns:
        if col in ['T Level']:
            sim_data[col] = np.random.choice(original_X[col].unique(), num_simulations)
        else:
            min_val, max_val = original_X[col].min(), original_X[col].max()
            sim_data[col] = np.random.uniform(min_val, max_val, num_simulations)
    
    simulation_df = pd.DataFrame(sim_data)
    sim_predictions = model.predict(simulation_df)

    output_columns = ['Step Coverage (SC, %)', 'Depo Rate (nm/cycle)', 'C/H Impurity (at.%)', 'Particle Density (cm-3)']
    for i, col_name in enumerate(output_columns):
        simulation_df[f'predicted_{col_name}'] = sim_predictions[:, i]

    # ìµœì í™” ëª©í‘œì— ë”°ë¼ ì •ë ¬ ë°©í–¥ ê²°ì •
    # ë¶ˆìˆœë¬¼, íŒŒí‹°í´ ë°€ë„ëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    ascending_order = optimization_target in ['C/H Impurity (at.%)', 'Particle Density (cm-3)']
    optimal_conditions = simulation_df.sort_values(by=f'predicted_{optimization_target}', ascending=ascending_order)
    
    return optimal_conditions

# --- Streamlit ì›¹ UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ­ ALD ê³µì • ìµœì í™” AI ì‹œë®¬ë ˆì´í„°")

# 1. íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="csv")

if uploaded_file:
    df = load_and_clean_data(uploaded_file)
    
    if df is not None:
        st.success("âœ… ë°ì´í„° ë¡œë”© ë° ì •ì œ ì™„ë£Œ!")
        st.dataframe(df.head())

        # 2. ëª¨ë¸ í•™ìŠµ
        model, X_data, eval_metrics = train_model(df)

        if model:
            st.success("âœ… AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            with st.expander("ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ë³´ê¸° (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)"):
                st.json({k: round(v, 4) for k, v in eval_metrics.items()})

            # 3. ìµœì í™” ì¡°ê±´ ì„¤ì • ë° ì‹¤í–‰
            st.header("âš™ï¸ ìµœì  ê³µì • ì¡°ê±´ íƒìƒ‰")
            optimization_target = st.selectbox(
                "ì–´ë–¤ ê°’ì„ ìµœì í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                ('Step Coverage (SC, %)', 'Depo Rate (nm/cycle)', 'C/H Impurity (at.%)', 'Particle Density (cm-3)'),
                help="Step Coverageì™€ Depo RateëŠ” ìµœëŒ€í™”, Impurityì™€ Particle DensityëŠ” ìµœì†Œí™”í•˜ëŠ” ì¡°ê±´ì„ ì°¾ìŠµë‹ˆë‹¤."
            )
            num_simulations = st.slider("ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 1000, 50000, 10000, 1000)

            if st.button("ğŸš€ ìµœì  ì¡°ê±´ íƒìƒ‰ ì‹œì‘!"):
                with st.spinner("AIê°€ ìˆ˜ë§Œ ê°œì˜ ê°€ìƒ ì¡°ê±´ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì…ë‹ˆë‹¤..."):
                    optimal_df = find_optimal_conditions(model, X_data, optimization_target, num_simulations)
                
                st.success("âœ¨ ìµœì  ì¡°ê±´ íƒìƒ‰ ì™„ë£Œ!")
                st.dataframe(optimal_df.head(10))